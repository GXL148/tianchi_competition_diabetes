{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from dateutil.parser import parse\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import Booster as lgbm_Booster\n",
    "from xgboost import Booster as xgb_Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/tc/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'd_train_20180102.csv', encoding='gb2312')\n",
    "test = pd.read_csv(data_path + 'd_test_A_20180102.csv', encoding='gb2312')\n",
    "\n",
    "def make_feat(train, test):\n",
    "    merge = pd.concat([train, test])\n",
    "    n_train = len(train)\n",
    "    train_y = merge['血糖']\n",
    "    merge = merge.drop(['血糖'], axis=1)\n",
    "    merge = merge.drop(['id', '乙肝表面抗原', '乙肝表面抗体', '乙肝e抗原', '乙肝e抗体', '乙肝核心抗体'], axis=1)\n",
    "    merge.fillna(merge.median(axis=0), inplace=True)\n",
    "\n",
    "    # 性别\n",
    "    d_sex = pd.get_dummies(merge['性别'])\n",
    "    merge = pd.concat([d_sex, merge], axis=1)\n",
    "    merge = merge.drop(['性别'], axis=1)\n",
    "\n",
    "    # 季节\n",
    "    merge['季节'] = pd.to_datetime(merge['体检日期']).dt.month\n",
    "    d_season = pd.get_dummies(merge['季节'], prefix=\"季节\")\n",
    "    merge = pd.concat([d_season, merge], axis=1)\n",
    "    merge = merge.drop(['季节'], axis=1)\n",
    "    merge['体检日期'] = (pd.to_datetime(merge['体检日期']) - parse('2017-10-09')).dt.days\n",
    "\n",
    "    # 年龄\n",
    "    def age_level(line):\n",
    "        age = line['年龄']\n",
    "        if age < 30:\n",
    "            return \"age_0_30\"\n",
    "        elif age >= 30 and age < 45:\n",
    "            return \"age_30_45\"\n",
    "        elif age >= 45 and age < 60:\n",
    "            return \"age_45_60\"\n",
    "        else:\n",
    "            return \"age_60_100\"\n",
    "\n",
    "    merge['年龄_LEVEL'] = merge.apply(age_level, axis=1)\n",
    "    d_age = pd.get_dummies(merge['年龄_LEVEL'], prefix=\"年龄\")\n",
    "    merge = pd.concat([d_age, merge], axis=1)\n",
    "    merge = merge.drop(['年龄_LEVEL'], axis=1)\n",
    "\n",
    "    X, y = merge[:n_train], train_y[:n_train]\n",
    "    test_X = merge[n_train:]\n",
    "\n",
    "    return X, y, test_X\n",
    "\n",
    "X, y, test_X = make_feat(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 1000 #用于分类 取血糖最高1000 和 血糖最低1000\n",
    "threshold = 10 #定义高血糖的阈值\n",
    "other = 20 #用于低血糖回归训练集 排序血糖最高的20个， 高血糖回归训练集使用topk\n",
    "\n",
    "sort_train = train.sort_values(by=\"血糖\", ascending=False) #按血糖排序\n",
    "high_index = sort_train[0:topk].index \n",
    "low_index = sort_train[-topk:].index\n",
    "\n",
    "other_index = sort_train[20:].index #用于低血糖回归训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高低血糖分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low_index = np.concatenate((high_index, low_index))\n",
    "clf_X, clf_y =  X.loc[high_low_index], np.where(y.loc[high_low_index] > threshold, 1, 0)\n",
    "clf_xgb_params = {\n",
    "    'booster':'gbtree',\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth': 8,\n",
    "    'eta':0.01,\n",
    "    'min_child_weight':3,\n",
    "    'colsample':0.8,\n",
    "    'scale_pos_weight':1,\n",
    "    'gamma':1,\n",
    "    'n_thread':4,\n",
    "    'silent':1\n",
    " }\n",
    "\n",
    "clf_xgb_train = xgb.DMatrix(clf_X, clf_y)\n",
    "watchlist = [(clf_xgb_train,'train')]\n",
    "clf_xgb_model = xgb.train(clf_xgb_params, clf_xgb_train, num_boost_round=1000,\n",
    "                          verbose_eval=200, evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_high = clf_xgb_model.predict(xgb.DMatrix(test_X)) #分类预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "血糖回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#固定参数设置\n",
    "xgb_params1 = {\n",
    "    'objective':\"reg:linear\",\n",
    "    'max_depth':5,\n",
    "    'eta':0.01,\n",
    "    'gamma':0.02,\n",
    "    'subsample':0.5,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "lgb_params1 = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "lgb_params2 = {\n",
    "    'learning_rate': 0.05,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'sub_feature': 0.2,\n",
    "    'num_leaves': 120,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'feature_fraction': 0.5,\n",
    "    'min_data': 50,\n",
    "    'min_hessian': 2,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "lgb_params3 = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mse',\n",
    "    'sub_feature': 0.5,\n",
    "    'num_leaves': 30,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'feature_fraction': 0.6,\n",
    "    'min_data': 3,\n",
    "    'min_hessian': 3,\n",
    "    'verbose': -1,\n",
    "}\n",
    "lgb_params1['is_unbalance']='true'\n",
    "lgb_params2['is_unbalance']='true'\n",
    "lgb_params3['is_unbalance']='true'\n",
    "\n",
    "def evalerror(pred, df):\n",
    "    label = df.get_label().values.copy()\n",
    "    score = mean_squared_error(label, pred) * 0.5\n",
    "    return ('0.5mse', score, False)\n",
    "\n",
    "def blending(models, weights, X, n_y):\n",
    "    y = np.zeros(n_y)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        if isinstance(model, lgbm_Booster):\n",
    "            #y_i = model.predict(X, num_iteration=model.best_iteration + 20)\n",
    "            y_i = model.predict(X)\n",
    "        else:\n",
    "            #y_i = model.predict(xgb.DMatrix(X), ntree_limit=model.best_ntree_limit + 20)\n",
    "            y_i = model.predict(xgb.DMatrix(X))\n",
    "\n",
    "        y += y_i * weights[i]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K折交叉验证\n",
    "def k_fold_predict(X, y, test_X, k=5):\n",
    "    print('start K Fold train...')\n",
    "    t0 = time.time()\n",
    "    kf = KFold(len(X), n_folds=k, shuffle=True)\n",
    "    X_preds = np.zeros(X.shape[0])\n",
    "    test_preds = np.zeros((test_X.shape[0], 5))\n",
    "    for i, (train_index, valid_index) in enumerate(kf):\n",
    "        train_X, train_y = X.iloc[train_index], y.iloc[train_index]\n",
    "        valid_X, valid_y = X.iloc[valid_index], y.iloc[valid_index]\n",
    "        xgb_train = xgb.DMatrix(train_X, train_y)\n",
    "        xgb_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    \n",
    "        xgb_model = xgb.train(xgb_params1,\n",
    "                              xgb_train,\n",
    "                              num_boost_round=3000,\n",
    "                              evals=[(xgb_valid, 'eval'), (xgb_train, 'train')],\n",
    "                              verbose_eval=500)\n",
    "    \n",
    "        lgb_train = lgb.Dataset(train_X, train_y)\n",
    "        lgb_valid = lgb.Dataset(valid_X, valid_y)\n",
    "        \n",
    "        gbm_model1 = lgb.train(lgb_params1,\n",
    "                               lgb_train,\n",
    "                               num_boost_round=3000,\n",
    "                               valid_sets=lgb_valid,\n",
    "                               verbose_eval=500,\n",
    "                               feval=evalerror,\n",
    "                               early_stopping_rounds=100)\n",
    "    \n",
    "        gbm_model2 = lgb.train(lgb_params2,\n",
    "                               lgb_train,\n",
    "                               num_boost_round=4500,\n",
    "                               valid_sets=lgb_valid,\n",
    "                               verbose_eval=500,\n",
    "                               feval=evalerror,\n",
    "                               early_stopping_rounds=500)\n",
    "    \n",
    "        gbm_model3 = lgb.train(lgb_params3,\n",
    "                               lgb_train,\n",
    "                               num_boost_round=5000,\n",
    "                               valid_sets=lgb_valid,\n",
    "                               verbose_eval=500,\n",
    "                               feval=evalerror,\n",
    "                               early_stopping_rounds=500)\n",
    "        W = [0.1,0.35,0.25,0.3]\n",
    "        M = [xgb_model, gbm_model1, gbm_model2, gbm_model3]\n",
    "        X_pred = blending(M, W, valid_X, len(valid_X))\n",
    "        test_pred = blending(M, W, test_X, len(test_X))\n",
    "        X_preds[valid_index] += X_pred\n",
    "        test_preds[:, i] = test_pred\n",
    "    print('train cv score：{}'.format(mean_squared_error(y, X_preds) * 0.5))\n",
    "    print('cv cost time {}'.format(time.time() - t0))\n",
    "    \n",
    "    return test_preds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分别训练高低两个回归模型\n",
    "X_high, y_high = X.loc[high_index], y.loc[high_index]\n",
    "X_low, y_low = X.loc[other_index], y.loc[other_index]\n",
    "\n",
    "mask = test_pred_high > 0.5\n",
    "final_sub = pd.Series(np.zeros(test_X.shape[0]))\n",
    "final_sub[mask] = k_fold_predict(X_high, y_high, test_X[mask])\n",
    "final_sub[~mask] = k_fold_predict(X_low, y_low, test_X[~mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313    10.060669\n601     8.746518\n938    11.154725\ndtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sub[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
